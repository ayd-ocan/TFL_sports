{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ocanaydin/football-cricket-basebal-transfer-learning?scriptVersionId=113934382\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DIVIDE DATASET AS TRAIN AND VALIDATION.**","metadata":{}},{"cell_type":"code","source":"base_dir = \"../input/cricket-football-baseball/cricket-football-baseball\"\nclasses = os.listdir(base_dir)\nfor i in range(len(classes)):\n    path = os.path.join(base_dir,classes[i])\n    print(f\"{classes[i]} has {len(os.listdir(path))} images\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:27.421176Z","iopub.execute_input":"2022-07-19T19:49:27.421965Z","iopub.status.idle":"2022-07-19T19:49:27.436854Z","shell.execute_reply.started":"2022-07-19T19:49:27.42193Z","shell.execute_reply":"2022-07-19T19:49:27.435788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:28.96893Z","iopub.execute_input":"2022-07-19T19:49:28.970049Z","iopub.status.idle":"2022-07-19T19:49:37.111268Z","shell.execute_reply.started":"2022-07-19T19:49:28.970011Z","shell.execute_reply":"2022-07-19T19:49:37.110207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"All images will be scaled 1/255 to normalize pixels between 0-1.Also image augmentation is used.\"\"\"\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255,rotation_range = 40,width_shift_range = 0.2,height_shift_range = 0.2,shear_range = 0.2,\n    zoom_range = 0.2,horizontal_flip = True,fill_mode = \"nearest\" ,validation_split = 0.2\n)\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,validation_split = 0.2)\n\ntrain_generator = train_datagen.flow_from_directory(base_dir,target_size = (300,300),class_mode = \"categorical\",\n                                                                  batch_size = 4,subset = \"training\",seed = 42)\nvalidation_generator = validation_datagen.flow_from_directory(base_dir,target_size = (300,300),class_mode = \"categorical\",\n                                                         batch_size =4,subset = \"validation\",seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:37.112918Z","iopub.execute_input":"2022-07-19T19:49:37.11351Z","iopub.status.idle":"2022-07-19T19:49:38.543943Z","shell.execute_reply.started":"2022-07-19T19:49:37.113479Z","shell.execute_reply":"2022-07-19T19:49:38.542619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN ARCHITECTURE WITH TRANSFER LEARNING**","metadata":{}},{"cell_type":"markdown","source":"**(1)Use InceptionV3 as base model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nbase_model = InceptionV3(input_shape = (300,300,3),include_top = False,weights = \"imagenet\")\n\"\"\"Freeze all layers to stop updating InceptionV3 trained weights.\"\"\"\nfor layer in base_model.layers:\n    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:49.886548Z","iopub.execute_input":"2022-07-19T19:49:49.886982Z","iopub.status.idle":"2022-07-19T19:49:55.866202Z","shell.execute_reply.started":"2022-07-19T19:49:49.886949Z","shell.execute_reply":"2022-07-19T19:49:55.865021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(2)Create an architecture to feed model with images.**","metadata":{}},{"cell_type":"code","source":"\"\"\"Here we can get the last layer as mixed8.It means that we can start updating our weights from mixed8 layer.\"\"\"\n\"\"\"You can change it if you want.\"\"\"\nlast_layer = base_model.get_layer(\"mixed8\")\nprint(last_layer.output_shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:57.654015Z","iopub.execute_input":"2022-07-19T19:49:57.654696Z","iopub.status.idle":"2022-07-19T19:49:57.662282Z","shell.execute_reply.started":"2022-07-19T19:49:57.654661Z","shell.execute_reply":"2022-07-19T19:49:57.660885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Flatten layer to reduce output shape to 1dim.\"\"\"\nx = tf.keras.layers.Flatten()(last_layer.output)\n\"\"\"Add fully connected layers with 256 units.\"\"\"\nx = tf.keras.layers.Dense(256,activation = \"relu\")(x)\n\"\"\"Add Dropout layer.\"\"\"\nx = tf.keras.layers.Dropout(0.2)(x)\n\"\"\"Output layer.\"\"\"\nx = tf.keras.layers.Dense(len(classes),activation = \"softmax\")(x)\n\"\"\"Here we can connect our model end to end.\"\"\"\nmodel = tf.keras.models.Model(base_model.input,x)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:49:59.642003Z","iopub.execute_input":"2022-07-19T19:49:59.642397Z","iopub.status.idle":"2022-07-19T19:49:59.86799Z","shell.execute_reply.started":"2022-07-19T19:49:59.642366Z","shell.execute_reply":"2022-07-19T19:49:59.866809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**COMPILE AND FIT MODEL**","metadata":{}},{"cell_type":"code","source":"model.compile(tf.keras.optimizers.RMSprop(learning_rate = 0.005),loss = \"categorical_crossentropy\",metrics = [\"acc\"])\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs = {}):\n        if logs.get(\"acc\") > 0.95:\n            print(\"Accuracy reached %95.Stop training.\")\n            self.model.stop_training = True \n\ncallback = myCallback()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:50:31.790172Z","iopub.execute_input":"2022-07-19T19:50:31.790911Z","iopub.status.idle":"2022-07-19T19:50:31.813313Z","shell.execute_reply.started":"2022-07-19T19:50:31.790878Z","shell.execute_reply":"2022-07-19T19:50:31.81166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,epochs = 30,batch_size = 4,validation_data = validation_generator,verbose = 1,\n                   callbacks = [callback])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T19:50:33.090206Z","iopub.execute_input":"2022-07-19T19:50:33.091275Z","iopub.status.idle":"2022-07-19T20:10:33.612536Z","shell.execute_reply.started":"2022-07-19T19:50:33.091237Z","shell.execute_reply":"2022-07-19T20:10:33.611481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PLOT LOSS AND ACCURACY**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\"\"\"Plot accuracy\"\"\"\nacc = history.history[\"acc\"]\nval_acc = history.history[\"val_acc\"]\nepochs = range(30)\nplt.plot(epochs,acc,label = \"Training Accuracy\")\nplt.plot(epochs,val_acc,label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:11:54.219488Z","iopub.execute_input":"2022-07-19T20:11:54.220132Z","iopub.status.idle":"2022-07-19T20:11:54.431994Z","shell.execute_reply.started":"2022-07-19T20:11:54.220092Z","shell.execute_reply":"2022-07-19T20:11:54.430644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(30)\nplt.plot(epochs,loss,label = \"Training Loss\")\nplt.plot(epochs,val_loss,label = \"Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:13:10.325376Z","iopub.execute_input":"2022-07-19T20:13:10.326002Z","iopub.status.idle":"2022-07-19T20:13:10.617384Z","shell.execute_reply.started":"2022-07-19T20:13:10.325965Z","shell.execute_reply":"2022-07-19T20:13:10.615494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SAVE MODEL AND LOAD MODEL**","metadata":{}},{"cell_type":"code","source":"model.save(\"football_cricket_baseball_TFL.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:16:35.376349Z","iopub.execute_input":"2022-07-19T20:16:35.376798Z","iopub.status.idle":"2022-07-19T20:16:36.124194Z","shell.execute_reply.started":"2022-07-19T20:16:35.376766Z","shell.execute_reply":"2022-07-19T20:16:36.122841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = tf.keras.models.load_model(\"football_cricket_baseball_TFL.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:17:10.947182Z","iopub.execute_input":"2022-07-19T20:17:10.94763Z","iopub.status.idle":"2022-07-19T20:17:13.147319Z","shell.execute_reply.started":"2022-07-19T20:17:10.947597Z","shell.execute_reply":"2022-07-19T20:17:13.14588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GET THE IMAGES FROM INTERNET AND PROCESS THEM**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\nimport numpy as np\n\ndef get_and_process(url):\n        response = requests.get(url)\n        img = Image.open(BytesIO(response.content))\n        img1 = img\n        \"\"\"Resize image for appropriate shape for model.\"\"\"\n        img = img.resize((300,300))\n        \"\"\"Convert img to numpy array,rescale it ,expand dims for model convenience. then check vertically.\"\"\"\n        x = tf.keras.preprocessing.image.img_to_array(img)\n        x = x / 255.0\n        x = np.expand_dims(x,axis = 0)\n        img_tensor = np.vstack([x])\n        return img1,img_tensor","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:37:02.181025Z","iopub.execute_input":"2022-07-19T20:37:02.181442Z","iopub.status.idle":"2022-07-19T20:37:02.190381Z","shell.execute_reply.started":"2022-07-19T20:37:02.181393Z","shell.execute_reply":"2022-07-19T20:37:02.18905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FINAL : PREDICT IMAGE**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nurl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Marcus_Thames_Tigers_2007.jpg/1200px-Marcus_Thames_Tigers_2007.jpg\"\nimg1,test_img = get_and_process(url)\npred = model1.predict(test_img)\nclasses = list(train_generator.class_indices.keys())\nprint(f\"Prediction is : {classes[np.argmax(pred)]}\")\nplt.imshow(img1)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:43:57.690066Z","iopub.execute_input":"2022-07-19T20:43:57.690927Z","iopub.status.idle":"2022-07-19T20:43:59.650284Z","shell.execute_reply.started":"2022-07-19T20:43:57.690887Z","shell.execute_reply":"2022-07-19T20:43:59.649033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}